{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Book Detection System - Visual Results Demo\n",
    "## Image Processing and Computer Vision - Assignment Module #1\n",
    "\n",
    "This notebook demonstrates the book detection system with visual results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "from IPython.display import display, HTML\n",
    "from book_detector_solution import UltimateBookDetector, Detection\n",
    "%matplotlib inline\n",
    "\n",
    "# Set up larger figure sizes\n",
    "plt.rcParams['figure.figsize'] = [15, 10]\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize the Detector and Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize detector\n",
    "detector = UltimateBookDetector()\n",
    "\n",
    "# Load all model books\n",
    "models_dir = \"dataset/dataset/models\"\n",
    "detector.load_models(models_dir)\n",
    "\n",
    "print(f\"\\nLoaded {len(detector.models)} book models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Display Sample Model Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a grid of model books\n",
    "model_files = sorted([f for f in os.listdir(models_dir) if f.endswith('.png')])[:12]\n",
    "\n",
    "fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, model_file in enumerate(model_files):\n",
    "    img = cv2.imread(os.path.join(models_dir, model_file))\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    axes[i].imshow(img_rgb)\n",
    "    axes[i].set_title(f\"{model_file.replace('.png', '')}\", fontsize=12)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Sample Model Books (References)', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Process Scenes and Show Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_detection_results(scene_name, show_original=True):\n",
    "    \"\"\"Display original scene and detection results side by side\"\"\"\n",
    "    \n",
    "    scene_path = f\"dataset/dataset/scenes/{scene_name}.jpg\"\n",
    "    result_path = f\"results/{scene_name}_detected.jpg\"\n",
    "    \n",
    "    # Check if detection result exists\n",
    "    if not os.path.exists(result_path):\n",
    "        # No detections for this scene\n",
    "        scene_img = cv2.imread(scene_path)\n",
    "        if scene_img is not None:\n",
    "            scene_rgb = cv2.cvtColor(scene_img, cv2.COLOR_BGR2RGB)\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            plt.imshow(scene_rgb)\n",
    "            plt.title(f\"{scene_name} - No Books Detected\", fontsize=14)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "        return\n",
    "    \n",
    "    # Load images\n",
    "    scene_img = cv2.imread(scene_path)\n",
    "    result_img = cv2.imread(result_path)\n",
    "    \n",
    "    # Convert to RGB\n",
    "    scene_rgb = cv2.cvtColor(scene_img, cv2.COLOR_BGR2RGB)\n",
    "    result_rgb = cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    if show_original:\n",
    "        # Show side by side\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "        \n",
    "        ax1.imshow(scene_rgb)\n",
    "        ax1.set_title('Original Scene', fontsize=14)\n",
    "        ax1.axis('off')\n",
    "        \n",
    "        ax2.imshow(result_rgb)\n",
    "        ax2.set_title('Detection Results', fontsize=14)\n",
    "        ax2.axis('off')\n",
    "        \n",
    "        plt.suptitle(f'{scene_name}', fontsize=16)\n",
    "    else:\n",
    "        # Show only results\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        plt.imshow(result_rgb)\n",
    "        plt.title(f'{scene_name} - Detection Results', fontsize=14)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Show text results\n",
    "    text_path = f\"results/{scene_name}_results.txt\"\n",
    "    if os.path.exists(text_path):\n",
    "        with open(text_path, 'r') as f:\n",
    "            print(f\"\\nDetection Details for {scene_name}:\")\n",
    "            print(\"=\"*50)\n",
    "            print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Best Detection Results\n",
    "Let's look at scenes with the most detections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load summary to find best scenes\n",
    "with open('results/summary.json', 'r') as f:\n",
    "    summary = json.load(f)\n",
    "\n",
    "# Sort scenes by number of detections\n",
    "scenes_sorted = sorted(summary['results'], key=lambda x: x['detections'], reverse=True)\n",
    "\n",
    "# Display top 3 scenes with most detections\n",
    "print(\"Top scenes with most detections:\\n\")\n",
    "for scene in scenes_sorted[:3]:\n",
    "    if scene['detections'] > 0:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Scene: {scene['scene']} - {scene['detections']} books detected\")\n",
    "        print(f\"{'='*60}\")\n",
    "        display_detection_results(scene['scene'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Typical Detection Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some typical detection examples\n",
    "typical_scenes = ['scene_5', 'scene_18', 'scene_26']\n",
    "\n",
    "for scene_name in typical_scenes:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    display_detection_results(scene_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Detection Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations of detection statistics\n",
    "detections_per_scene = [r['detections'] for r in summary['results']]\n",
    "scene_names = [r['scene'] for r in summary['results']]\n",
    "\n",
    "# 1. Histogram of detections\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(detections_per_scene, bins=range(0, max(detections_per_scene)+2), \n",
    "         edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Number of Books Detected', fontsize=12)\n",
    "plt.ylabel('Number of Scenes', fontsize=12)\n",
    "plt.title('Distribution of Detection Counts Across Scenes', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# 2. Bar chart of detections per scene\n",
    "plt.figure(figsize=(18, 6))\n",
    "bars = plt.bar(range(len(scene_names)), detections_per_scene, \n",
    "                color=['green' if d > 0 else 'red' for d in detections_per_scene])\n",
    "plt.xticks(range(len(scene_names)), scene_names, rotation=90)\n",
    "plt.xlabel('Scene', fontsize=12)\n",
    "plt.ylabel('Number of Books Detected', fontsize=12)\n",
    "plt.title('Books Detected per Scene', fontsize=14)\n",
    "plt.grid(True, axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, count in zip(bars, detections_per_scene):\n",
    "    if count > 0:\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, \n",
    "                str(count), ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Summary statistics\n",
    "print(\"\\nDetection Summary Statistics:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total scenes processed: {summary['total_scenes']}\")\n",
    "print(f\"Total books detected: {summary['total_detections']}\")\n",
    "print(f\"Average books per scene: {summary['average_per_scene']:.2f}\")\n",
    "print(f\"Scenes with detections: {sum(1 for d in detections_per_scene if d > 0)} ({sum(1 for d in detections_per_scene if d > 0)/len(detections_per_scene)*100:.1f}%)\")\n",
    "print(f\"Scenes without detections: {sum(1 for d in detections_per_scene if d == 0)} ({sum(1 for d in detections_per_scene if d == 0)/len(detections_per_scene)*100:.1f}%)\")\n",
    "print(f\"Maximum books in a scene: {max(detections_per_scene)}\")\n",
    "print(f\"Average processing time: {summary['total_time']/summary['total_scenes']:.2f} seconds/scene\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Matching Visualization\n",
    "Let's visualize how the feature matching works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_feature_matching(model_id, scene_name):\n",
    "    \"\"\"Visualize feature matching between a model and scene\"\"\"\n",
    "    \n",
    "    # Load images\n",
    "    model_path = f\"dataset/dataset/models/{model_id}.png\"\n",
    "    scene_path = f\"dataset/dataset/scenes/{scene_name}.jpg\"\n",
    "    \n",
    "    model_img = cv2.imread(model_path)\n",
    "    scene_img = cv2.imread(scene_path)\n",
    "    \n",
    "    # Preprocess\n",
    "    model_gray = detector.preprocess_image(model_img)\n",
    "    scene_gray = detector.preprocess_image(scene_img)\n",
    "    \n",
    "    # Extract features\n",
    "    model_kp, model_desc = detector.sift.detectAndCompute(model_gray, None)\n",
    "    scene_kp, scene_desc = detector.sift.detectAndCompute(scene_gray, None)\n",
    "    \n",
    "    # Match features\n",
    "    matches = detector.matcher.knnMatch(model_desc, scene_desc, k=2)\n",
    "    \n",
    "    # Apply ratio test\n",
    "    good = []\n",
    "    for match_pair in matches:\n",
    "        if len(match_pair) == 2:\n",
    "            m, n = match_pair\n",
    "            if m.distance < 0.75 * n.distance:\n",
    "                good.append(m)\n",
    "    \n",
    "    # Draw matches\n",
    "    img_matches = cv2.drawMatches(model_img, model_kp, scene_img, scene_kp, \n",
    "                                 good[:50], None, flags=cv2.DrawMatchesFlags_DEFAULT)\n",
    "    \n",
    "    # Display\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    plt.imshow(cv2.cvtColor(img_matches, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f'Feature Matching: {model_id} in {scene_name} ({len(good)} good matches)', fontsize=14)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Model keypoints: {len(model_kp)}\")\n",
    "    print(f\"Scene keypoints: {len(scene_kp)}\")\n",
    "    print(f\"Good matches: {len(good)}\")\n",
    "\n",
    "# Example: Show feature matching for a successful detection\n",
    "visualize_feature_matching('model_13', 'scene_5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Detection Confidence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze detection confidence scores\n",
    "all_confidences = []\n",
    "all_model_ids = []\n",
    "\n",
    "# Parse all result files to get confidence scores\n",
    "for scene in summary['results']:\n",
    "    if scene['detections'] > 0:\n",
    "        # Read the detailed results\n",
    "        scene_path = f\"dataset/dataset/scenes/{scene['scene']}.jpg\"\n",
    "        detections = detector.detect_all_books(scene_path)\n",
    "        \n",
    "        for det in detections:\n",
    "            all_confidences.append(det.confidence)\n",
    "            all_model_ids.append(det.model_id)\n",
    "\n",
    "if all_confidences:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Confidence distribution\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(all_confidences, bins=20, edgecolor='black', alpha=0.7)\n",
    "    plt.xlabel('Confidence Score', fontsize=12)\n",
    "    plt.ylabel('Number of Detections', fontsize=12)\n",
    "    plt.title('Distribution of Detection Confidence Scores', fontsize=14)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Model detection frequency\n",
    "    plt.subplot(1, 2, 2)\n",
    "    from collections import Counter\n",
    "    model_counts = Counter(all_model_ids)\n",
    "    models = list(model_counts.keys())\n",
    "    counts = list(model_counts.values())\n",
    "    \n",
    "    plt.bar(range(len(models)), counts)\n",
    "    plt.xticks(range(len(models)), models, rotation=90)\n",
    "    plt.xlabel('Model ID', fontsize=12)\n",
    "    plt.ylabel('Number of Detections', fontsize=12)\n",
    "    plt.title('Detection Frequency by Model', fontsize=14)\n",
    "    plt.grid(True, axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nAverage confidence: {np.mean(all_confidences):.3f}\")\n",
    "    print(f\"Median confidence: {np.median(all_confidences):.3f}\")\n",
    "    print(f\"Min confidence: {min(all_confidences):.3f}\")\n",
    "    print(f\"Max confidence: {max(all_confidences):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Interactive Scene Explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an interactive function to explore any scene\n",
    "def explore_scene(scene_number):\n",
    "    \"\"\"Interactively explore a specific scene\"\"\"\n",
    "    scene_name = f\"scene_{scene_number}\"\n",
    "    display_detection_results(scene_name, show_original=True)\n",
    "\n",
    "# Example usage - change the number to explore different scenes\n",
    "explore_scene(15)  # Scene with most detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusions\n",
    "\n",
    "### Detection Performance:\n",
    "- **Total books detected**: 26 across 29 scenes\n",
    "- **Average detection rate**: 0.9 books per scene\n",
    "- **Success rate**: 45% of scenes have at least one detection\n",
    "\n",
    "### Key Observations:\n",
    "1. The system successfully detects books using SIFT features and homography\n",
    "2. Detection works best when books have distinctive features and good contrast\n",
    "3. Multiple instances of the same book can be detected in some cases\n",
    "4. Low confidence scores suggest room for parameter optimization\n",
    "\n",
    "### Technical Achievements:\n",
    "- ✅ Traditional CV approach (no deep learning)\n",
    "- ✅ Proper bounding boxes with corner coordinates\n",
    "- ✅ Area calculation for each detection\n",
    "- ✅ Visual overlays on scene images\n",
    "- ✅ Required output format\n",
    "\n",
    "### Future Improvements:\n",
    "- Fine-tune detection parameters with ground truth data\n",
    "- Implement better multi-instance detection\n",
    "- Add rotation invariance for tilted books\n",
    "- Optimize processing speed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}