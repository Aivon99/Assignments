{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24101764",
   "metadata": {},
   "source": [
    "il data augmentation è fattp sul momento usando queste funzioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28eae921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as tF\n",
    "\n",
    "class Random90DegreeRotation:\n",
    "    \"\"\"Custom transform for 90-degree rotations with specific probabilities.\"\"\"\n",
    "    def __call__(self, img):\n",
    "        prob = random.random()\n",
    "        if prob < 0.5:\n",
    "            return img  # No rotation\n",
    "        elif prob < 0.75:\n",
    "            return tF.rotate(img, angle=-90)  # Rotate 90 degrees left\n",
    "        else:\n",
    "            return tF.rotate(img, angle=90)  # Rotate 90 degrees right\n",
    "\n",
    "class OuterRandomCrop:\n",
    "    \"\"\"Custom transform to randomly crop the same amount of pixels from each side of the image.\"\"\"\n",
    "    def __init__(self, max_pixels_to_crop):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            max_pixels_to_crop (int): The maximum number of pixels to subtract from each side of the image.\n",
    "        \"\"\"\n",
    "        self.max_pixels_to_crop = max_pixels_to_crop\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # decides whether to apply the crop (75% chance)\n",
    "        if random.random() < 0.25:\n",
    "            return img\n",
    "\n",
    "        # randomly select the number of pixels to crop (between 0 and max_pixels_to_crop)\n",
    "        pixels_to_crop = random.randint(0, self.max_pixels_to_crop)\n",
    "\n",
    "        width, height = img.size\n",
    "        crop_left = pixels_to_crop\n",
    "        crop_top = pixels_to_crop\n",
    "        crop_width = width - 2 * pixels_to_crop\n",
    "        crop_height = height - 2 * pixels_to_crop\n",
    "\n",
    "        if crop_width <= 0 or crop_height <= 0:\n",
    "            raise ValueError(\"The number of pixels to crop is too large for the image dimensions.\")\n",
    "\n",
    "        return tF.crop(img, top=crop_top, left=crop_left, height=crop_height, width=crop_width)\n",
    "\n",
    "\n",
    "convert_compatible = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),     # Deterministic resize\n",
    "    transforms.ToTensor(),             # Format conversion only\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # image net normalization values\n",
    "])\n",
    "\n",
    "transform_data_augmentation = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(0.5),       # Random horizontal flip\n",
    "    OuterRandomCrop(20),                 # Custom outer crop\n",
    "    Random90DegreeRotation(),                    # Custom 90-degree rotation\n",
    "    transforms.RandomRotation(10),              # Random rotation of ±10 degrees\n",
    "    transforms.ColorJitter(brightness=0.4),      # Adjust brightness slightly\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),                       # Convert to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # Normalize using ImageNet stats\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = OxfordPetDataset('train', transform=transform_data_augmentation)\n",
    "val_dataset = OxfordPetDataset('val', transform=convert_compatible)\n",
    "test_dataset = OxfordPetDataset('test', transform=convert_compatible)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6eda33",
   "metadata": {},
   "source": [
    "transform_data_augmentation è la pipeline. viene passata come argomento al dataset train_dataset. se copi e incolli quella cella (la trovi anche sul notebook train_resnet) dovrebbe uscirti lo stesso augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b64f67e",
   "metadata": {},
   "source": [
    "questa è la funzione di training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025ccf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10, show_all_minibatches_loss=False):\n",
    "    train_losses = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        tot_batches = train_loader.__len__()\n",
    "        for batch_idx, (batch_images, batch_labels) in enumerate(train_loader):\n",
    "\n",
    "            batch_images = batch_images.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "\n",
    "            # Zero gradients from previous iteration\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(batch_images)\n",
    "\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            if show_all_minibatches_loss or batch_idx in [40, 80]:\n",
    "                print(f\"Batch {batch_idx}/{tot_batches}: loss = {loss.item():.4f}\")\n",
    "\n",
    "            # compute gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():  # Don't compute gradients for validation\n",
    "            for batch_images, batch_labels in val_loader:\n",
    "                batch_images = batch_images.to(device)\n",
    "                batch_labels = batch_labels.to(device)\n",
    "\n",
    "                outputs = model(batch_images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += batch_labels.size(0)\n",
    "                correct += (predicted == batch_labels).sum().item()\n",
    "\n",
    "        val_accuracy = 100 * correct / total\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}, Val Acc: {val_accuracy:.2f}%')\n",
    "\n",
    "    return train_losses, val_accuracies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ebddab",
   "metadata": {},
   "source": [
    "puoi usare questa funzione per vedere se ti escono delle immagini simili a quelle sul notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4246fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Function to display images\n",
    "def display_image_comparison(dataset, num_images=4):\n",
    "    fig, axes = plt.subplots(3, num_images, figsize=(15, 10))  # 3 rows, num_images columns\n",
    "\n",
    "    for i in range(num_images):\n",
    "        # Randomly select an image from the dataset\n",
    "        idx = random.randint(0, len(dataset) - 1)\n",
    "\n",
    "        # Access the raw image without applying the dataset's transform\n",
    "        img_path = dataset.root / \"images\" / f\"{dataset.names[idx]}.jpg\"\n",
    "        original_img = Image.open(img_path).convert(\"RGB\")  # Load as PIL image\n",
    "        label = dataset.labels[idx]\n",
    "\n",
    "        # Apply your transformation\n",
    "        transformed_with_norm = transform_data_augmentation(original_img)  # Fully transformed with normalization\n",
    "\n",
    "        # Undo normalization for visualization\n",
    "        mean = [0.485, 0.456, 0.406]\n",
    "        std = [0.229, 0.224, 0.225]\n",
    "        transformed_with_norm_np = transformed_with_norm.permute(1, 2, 0).numpy()\n",
    "        transformed_no_norm_np = std * transformed_with_norm_np + mean  # Undo normalization\n",
    "        transformed_no_norm_np = transformed_no_norm_np.clip(0, 1)\n",
    "\n",
    "        # Display original image\n",
    "        axes[0, i].imshow(original_img)\n",
    "        axes[0, i].set_title(f\"Original (Label: {label})\")\n",
    "        axes[0, i].axis(\"off\")\n",
    "\n",
    "        # Display transformed image with normalization undone\n",
    "        axes[1, i].imshow(transformed_no_norm_np)\n",
    "        axes[1, i].set_title(\"Transformed (Norm Undone)\")\n",
    "        axes[1, i].axis(\"off\")\n",
    "\n",
    "        # Display fully transformed image (with normalization)\n",
    "        axes[2, i].imshow(transformed_with_norm_np)\n",
    "        axes[2, i].set_title(\"Transformed\")\n",
    "        axes[2, i].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to display the comparison\n",
    "display_image_comparison(train_dataset, num_images=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
