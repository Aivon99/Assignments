{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24101764",
   "metadata": {},
   "source": [
    "il data augmentation è fattp sul momento usando queste funzioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc665cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset\n",
    "from typing import List, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28eae921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as tF\n",
    "\n",
    "class Random90DegreeRotation:\n",
    "    \"\"\"Custom transform for 90-degree rotations with specific probabilities.\"\"\"\n",
    "    def __call__(self, img):\n",
    "        prob = random.random()\n",
    "        if prob < 0.5:\n",
    "            return img  # No rotation\n",
    "        elif prob < 0.75:\n",
    "            return tF.rotate(img, angle=-90)  # Rotate 90 degrees left\n",
    "        else:\n",
    "            return tF.rotate(img, angle=90)  # Rotate 90 degrees right\n",
    "\n",
    "class OuterRandomCrop:\n",
    "    \"\"\"Custom transform to randomly crop the same amount of pixels from each side of the image.\"\"\"\n",
    "    def __init__(self, max_pixels_to_crop):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            max_pixels_to_crop (int): The maximum number of pixels to subtract from each side of the image.\n",
    "        \"\"\"\n",
    "        self.max_pixels_to_crop = max_pixels_to_crop\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # decides whether to apply the crop (75% chance)\n",
    "        if random.random() < 0.25:\n",
    "            return img\n",
    "\n",
    "        # randomly select the number of pixels to crop (between 0 and max_pixels_to_crop)\n",
    "        pixels_to_crop = random.randint(0, self.max_pixels_to_crop)\n",
    "\n",
    "        width, height = img.size\n",
    "        crop_left = pixels_to_crop\n",
    "        crop_top = pixels_to_crop\n",
    "        crop_width = width - 2 * pixels_to_crop\n",
    "        crop_height = height - 2 * pixels_to_crop\n",
    "\n",
    "        if crop_width <= 0 or crop_height <= 0:\n",
    "            raise ValueError(\"The number of pixels to crop is too large for the image dimensions.\")\n",
    "\n",
    "        return tF.crop(img, top=crop_top, left=crop_left, height=crop_height, width=crop_width)\n",
    "\n",
    "\n",
    "convert_compatible = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),     # Deterministic resize\n",
    "    transforms.ToTensor(),             # Format conversion only\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # image net normalization values\n",
    "])\n",
    "\n",
    "transform_data_augmentation = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(0.5),       # Random horizontal flip\n",
    "    OuterRandomCrop(20),                 # Custom outer crop\n",
    "    Random90DegreeRotation(),                    # Custom 90-degree rotation\n",
    "    transforms.RandomRotation(10),              # Random rotation of ±10 degrees\n",
    "    transforms.ColorJitter(brightness=0.4),      # Adjust brightness slightly\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),                       # Convert to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # Normalize using ImageNet stats\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = OxfordPetDataset('train', transform=transform_data_augmentation)\n",
    "val_dataset = OxfordPetDataset('val', transform=convert_compatible)\n",
    "test_dataset = OxfordPetDataset('test', transform=convert_compatible)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6eda33",
   "metadata": {},
   "source": [
    "transform_data_augmentation è la pipeline. viene passata come argomento al dataset train_dataset. se copi e incolli quella cella (la trovi anche sul notebook train_resnet) dovrebbe uscirti lo stesso augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b64f67e",
   "metadata": {},
   "source": [
    "questa è la funzione di training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025ccf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10, show_all_minibatches_loss=False):\n",
    "    train_losses = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        tot_batches = train_loader.__len__()\n",
    "        for batch_idx, (batch_images, batch_labels) in enumerate(train_loader):\n",
    "\n",
    "            batch_images = batch_images.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "\n",
    "            # Zero gradients from previous iteration\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(batch_images)\n",
    "\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            if show_all_minibatches_loss or batch_idx in [40, 80]:\n",
    "                print(f\"Batch {batch_idx}/{tot_batches}: loss = {loss.item():.4f}\")\n",
    "\n",
    "            # compute gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():  # Don't compute gradients for validation\n",
    "            for batch_images, batch_labels in val_loader:\n",
    "                batch_images = batch_images.to(device)\n",
    "                batch_labels = batch_labels.to(device)\n",
    "\n",
    "                outputs = model(batch_images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += batch_labels.size(0)\n",
    "                correct += (predicted == batch_labels).sum().item()\n",
    "\n",
    "        val_accuracy = 100 * correct / total\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}, Val Acc: {val_accuracy:.2f}%')\n",
    "\n",
    "    return train_losses, val_accuracies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ebddab",
   "metadata": {},
   "source": [
    "puoi usare questa funzione per vedere se ti escono delle immagini simili a quelle sul notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4246fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Function to display images\n",
    "def display_image_comparison(dataset, num_images=4):\n",
    "    fig, axes = plt.subplots(3, num_images, figsize=(15, 10))  # 3 rows, num_images columns\n",
    "\n",
    "    for i in range(num_images):\n",
    "        # Randomly select an image from the dataset\n",
    "        idx = random.randint(0, len(dataset) - 1)\n",
    "\n",
    "        # Access the raw image without applying the dataset's transform\n",
    "        img_path = dataset.root / \"images\" / f\"{dataset.names[idx]}.jpg\"\n",
    "        original_img = Image.open(img_path).convert(\"RGB\")  # Load as PIL image\n",
    "        label = dataset.labels[idx]\n",
    "\n",
    "        # Apply your transformation\n",
    "        transformed_with_norm = transform_data_augmentation(original_img)  # Fully transformed with normalization\n",
    "\n",
    "        # Undo normalization for visualization\n",
    "        mean = [0.485, 0.456, 0.406]\n",
    "        std = [0.229, 0.224, 0.225]\n",
    "        transformed_with_norm_np = transformed_with_norm.permute(1, 2, 0).numpy()\n",
    "        transformed_no_norm_np = std * transformed_with_norm_np + mean  # Undo normalization\n",
    "        transformed_no_norm_np = transformed_no_norm_np.clip(0, 1)\n",
    "\n",
    "        # Display original image\n",
    "        axes[0, i].imshow(original_img)\n",
    "        axes[0, i].set_title(f\"Original (Label: {label})\")\n",
    "        axes[0, i].axis(\"off\")\n",
    "\n",
    "        # Display transformed image with normalization undone\n",
    "        axes[1, i].imshow(transformed_no_norm_np)\n",
    "        axes[1, i].set_title(\"Transformed (Norm Undone)\")\n",
    "        axes[1, i].axis(\"off\")\n",
    "\n",
    "        # Display fully transformed image (with normalization)\n",
    "        axes[2, i].imshow(transformed_with_norm_np)\n",
    "        axes[2, i].set_title(\"Transformed\")\n",
    "        axes[2, i].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to display the comparison\n",
    "display_image_comparison(train_dataset, num_images=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2550a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "# Load pretrained ResNet-18\n",
    "pretrained_resnet = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Adapt the final layer for 37 classes\n",
    "num_classes = 37\n",
    "pretrained_resnet.fc = nn.Linear(pretrained_resnet.fc.in_features, num_classes)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "pretrained_resnet = pretrained_resnet.to(device)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9513df0f",
   "metadata": {},
   "source": [
    "AGGIUNTE DA QUI IN GIU'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9151b09a",
   "metadata": {},
   "source": [
    "Prepare the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b4cc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = OxfordPetDataset('train', transform=transform_data_augmentation)\n",
    "val_dataset = OxfordPetDataset('val', transform=convert_compatible)\n",
    "test_dataset = OxfordPetDataset('test', transform=convert_compatible)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd312b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#We define a training function reusing the function prev defined \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(pretrained_resnet.parameters(), lr=0.001)\n",
    "\n",
    "train_losses, val_accuracies = train_model(\n",
    "    pretrained_resnet, train_loader, val_loader,\n",
    "    criterion, optimizer, num_epochs=60\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f051459f",
   "metadata": {},
   "source": [
    "Fine tune with previous hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9643dcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "batch_size = 32 \n",
    "epochs = 60     # max\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Reuse your existing dataset and transforms from part 1\n",
    "# Assuming: OxfordPetDataset, transform_data_augmentation, convert_compatible are already defined\n",
    "\n",
    "# 1. Load pretrained ResNet-18 and modify the final FC layer\n",
    "pretrained_resnet = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "num_classes = 37\n",
    "pretrained_resnet.fc = nn.Linear(pretrained_resnet.fc.in_features, num_classes)\n",
    "\n",
    "# 2. Set device and move model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "pretrained_resnet = pretrained_resnet.to(device)\n",
    "\n",
    "# 3. Create Data Loaders\n",
    "train_dataset = OxfordPetDataset('train', transform=transform_data_augmentation)\n",
    "val_dataset = OxfordPetDataset('val', transform=convert_compatible)\n",
    "test_dataset = OxfordPetDataset('test', transform=convert_compatible)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 4. Define Loss and Optimizer (same hyperparameters as part 1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(pretrained_resnet.parameters(), lr=0.001)\n",
    "\n",
    "# 5. Define Training Loop (reuse function from part 1)\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_acc = 100 * correct / total\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Val Accuracy: {val_acc:.2f}%\")\n",
    "\n",
    "# 6. Train the model\n",
    "train_model(pretrained_resnet, train_loader, val_loader, criterion, optimizer, num_epochs=60)\n",
    "\n",
    "# 7. Evaluate on Test Set\n",
    "pretrained_resnet.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = pretrained_resnet(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Final Test Accuracy (Part 2A): {100 * correct / total:.2f}%\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb05afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEPENDING ON ACCURACY RESULT PERHAPS WE SHOULD LOWER lr \n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "optimizer = torch.optim.Adam(pretrained_resnet.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b4028b",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af07a969",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_resnet.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_images, batch_labels in test_loader:\n",
    "        batch_images = batch_images.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "\n",
    "        outputs = pretrained_resnet(batch_images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        total += batch_labels.size(0)\n",
    "        correct += (predicted == batch_labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41de728a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e687fd9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c766491c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
